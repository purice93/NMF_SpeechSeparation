背景：语音分离的目的？
	语音分离的目标就是从这些干扰中分离出主说话人的语音（主要是主说话人）

问题分析：
	这里面主要是从混合语音中分离出主说话人，即去除干扰。
	根据干扰的不同，语音分离任务可以分为三类：
		1、当干扰为噪声信号时，可以称为“语音增强”（Speech Enhancement）
		2、当干扰为其他说话人时，可以称为“多说话人分离”（Speaker Separation）
		3、当干扰为目标说话人自己声音的反射波时，可以称为“解混响”（De-reverberation）

	多说话人分离分为三种情况：
		1、目标说话人和干扰说话人都固定，Speaker dependent，有监督分离
		2、目标说话人固定，训练阶段和测试阶段的干扰说话人可变，Target dependent，半监督分离（这个应该是我们的研究目标）
		3、目标说话人和干扰说话人都可变，Speaker independent，无监督分离
	
	方法：
		对于有监督和半监督分离，可以使用基于频谱映射的方法，与前面使用基于频谱映射的方法做语音增强类似。
		对于无监督分类，有无监督聚类、深度聚类以及最近的序列不变训练（PIT）方法。
			PIT方法的核心是红框中标出的部分，在误差回传的时候，
			分别计算输出序列和标注序列间各种组合的均方误差，然后从这些均方误差中找到最小的那个作为回传误差，
			也就是根据自动找到的声源间的最佳匹配进行优化，避免出现序列模糊的问题。

几个别人的问题：
	最后，文仕学给大家留了两个思考题，欢迎大家在评论给出自己的见解。
		1、第一个问题是语音分离任务中，是按传统思路先变换到频域，然后在频域上进行处理，
			还是直接在时域上处理比较好？后者的好处是端到端训练，不用考虑频域方法做傅立叶反变换时相位的问题。
		2、第二个问题是对于语音增强任务，应该使用真实噪声加噪还是使用人工仿真生成的噪声进行降噪？


	由于麦克风采集到的声音中可能包括噪声、其他人说话的声音、混响等干扰，
	不做语音分离、直接进行识别的话，会影响到识别的准确率。
	因此在语音识别的前端加上语音分离技术，把目标说话人的声音和其它干扰分开就可以提高语音识别系统的鲁棒性，
	这从而也成为现代语音识别系统中不可或缺的一环。

















补充：理想二值焱膜
我们也第一次把 CASA 和后来的深度学习结合了起来，也就是说把鸡尾酒会问题变成了一个机器学习问题。
早期的时候，我是通过神经动力学来做声源分离的。但现在我们把鸡尾酒会问题变成了一个分类问题，
源于我们称之为「理想二值模（Ideal Binary Mask）」。这是我们实验室提出的一个很重要的概念。
我们就想：什么叫解决了鸡尾酒会问题？也就是说，如果把一个听觉信号在时间域和频率域两个维度（时频二维）
进行表示（类似于视觉信号的 x 轴和 y 轴两个维度），你就可以把时频这二维表示成一个二维矩阵，
这个矩阵中的每一个元素称为一个「时频元（time-frequency unit）」。我们开始研究的就是怎么量化这个时频元，
后来我们发现这个量化只要二值就可以了——要么是 0 要么就是 1。这跟传统的声源处理方法是完全不一样的。
传统的声源处理要把信号分得很细。一个信号里面可能有很多的组成部分——一个部分属于这个声源，
另一个部分属于另一个声源。我们的方法就不需要分那么细，就只需要分一次——要么属于目标声源，
要么就是背景噪声。这就是「二值」的意思。这样我们就把 CASA 问题变成了一个监督学习（supervised learning）问题；
相对地，早期方法则是无监督的（unsupervised）——也就是说把一个信号的权值算一算，而不需要教它。
我们从理想二值模的角度考虑，就把它变成了一个分类问题。


因为这是一个全新的思路——原来是一个信号处理问题，现在变成了一个学习问题——而我们一直是领先在做


所以简单总结一下，CASA 就是基于人的听觉原理来做声源分离，我们实验室的最大贡献是第一次将这个问题变成了一个监督学习问题。
汪德亮：一旦把它变成了一个监督学习问题之后，我们就希望学习机的分类结果和理想二值模的分类是一样的。
理想二值模是「理想的」，是在声音没有重叠之前计算出来的，就是说不管噪声比目标声音强多少倍，
它都能将目标声音分离出来。尽管是二值的，但是功效非常之大。
其中的难点就在怎么通过学习的方式来不断地提高精度，让它不断接近理想二值模。
我想所有的监督学习都一样，就是说：我们可以怎样在数据有限的条件下学习到足够好的模型，并且可以推广到新的场景。